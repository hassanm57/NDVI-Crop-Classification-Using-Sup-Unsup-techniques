# -*- coding: utf-8 -*-
"""ML_Proj.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19M7d8AinZQITpUmnuoSDaVa_qAAxCS0m

Name: Hassan Mansoor

CMS: 403544

Class: BSCS12A

# Supervised Learning Algorithms

**Random Forests**

Mount Drive
"""

from google.colab import drive
drive.mount('/content/drive')

"""Importing The Data"""

import os
import pandas as pd

# Define the folder paths
base_path = '/content/drive/My Drive/Crop-dataset'
rice_folder = os.path.join(base_path, 'Rice')
cotton_folder = os.path.join(base_path, 'Cotton')

# Load CSV files
rice_2021 = pd.read_csv(os.path.join(rice_folder, 'rice2021.csv'))
rice_2022 = pd.read_csv(os.path.join(rice_folder, 'rice2022.csv'))
rice_2023 = pd.read_csv(os.path.join(rice_folder, 'rice2023.csv'))

cotton_2021 = pd.read_csv(os.path.join(cotton_folder, 'cotton2021.csv'))
cotton_2022 = pd.read_csv(os.path.join(cotton_folder, 'cotton2022.csv'))
cotton_2023 = pd.read_csv(os.path.join(cotton_folder, 'cotton2023.csv'))

"""Add Year Column To Each Datafile"""

# Add year column to each dataset
rice_2021['year'] = 2021
rice_2022['year'] = 2022
rice_2023['year'] = 2023

cotton_2021['year'] = 2021
cotton_2022['year'] = 2022
cotton_2023['year'] = 2023

# Verify the addition
print("Rice 2021 with year column:\n", rice_2021.head())
print("Cotton 2021 with year column:\n", cotton_2021.head())

# Add labels
rice_2021['label'] = 'rice'
rice_2022['label'] = 'rice'
rice_2023['label'] = 'rice'

cotton_2021['label'] = 'cotton'
cotton_2022['label'] = 'cotton'
cotton_2023['label'] = 'cotton'

print("Rice 2021 data:\n", rice_2021.head())
print("Cotton 2021 data:\n", cotton_2021.head())

"""# Combining The Datasets"""

import pandas as pd

# Combine rice datasets
rice_combined = pd.concat([rice_2021, rice_2022, rice_2023], axis=0)

# Combine cotton datasets
cotton_combined = pd.concat([cotton_2021, cotton_2022, cotton_2023], axis=0)

# Merge rice and cotton datasets
all_data = pd.concat([rice_combined, cotton_combined], axis=0).reset_index(drop=True)

print("Combined dataset:\n", all_data.head())
print("Shape of the dataset:", all_data.shape)

"""# Data Augmentation And Preprocessing

# Time Series Shifting
"""

# Identify NDVI columns
ndvi_columns = [col for col in all_data.columns if 'NDVI' in col]

# Shift cotton NDVI values forward to simulate earlier growth (by 2 months)
cotton_shifted = cotton_combined.copy()
cotton_shifted[ndvi_columns] = cotton_shifted[ndvi_columns].shift(periods=2, axis=0)

# Shift rice NDVI values backward to simulate later growth (by 2 months)
rice_shifted = rice_combined.copy()
rice_shifted[ndvi_columns] = rice_shifted[ndvi_columns].shift(periods=-2, axis=0)

# Combine the shifted datasets back with the original ones (for augmentation)
augmented_data = pd.concat([cotton_shifted, rice_shifted], axis=0).reset_index(drop=True)

"""Shifting the NDVI time series helps simulate different seasonal growth cycles for rice and cotton and introduces variability into the model.
This approach will make the model more adaptable to the natural seasonality of the crops, improving its performance.

Handle Missing Values
"""

# Check for missing values
missing_values = augmented_data.isnull().sum()

# Print missing values for each column
print("Missing values for each column:\n", missing_values)

"""Fill in missing values with mean"""

# Calculate the mean of each column (excluding non-numeric columns)
column_means = augmented_data.select_dtypes(include=['number']).mean()

# Fill missing values with the calculated means
augmented_data = augmented_data.fillna(column_means)

missing_values = augmented_data.isnull().sum()
# Print missing values for each column
print("Missing values for each column:\n", missing_values)

"""No missing values anymore!

# Normalize The NDVI Values
"""

from sklearn.preprocessing import MinMaxScaler

# Normalize NDVI columns
scaler = MinMaxScaler()
augmented_data[ndvi_columns] = scaler.fit_transform(augmented_data[ndvi_columns])

print("Normalized NDVI values:\n", augmented_data[ndvi_columns].head())

"""Feature Engineering"""

# Add mean NDVI and max NDVI as features
augmented_data['mean_ndvi'] = augmented_data[ndvi_columns].mean(axis=1)
augmented_data['max_ndvi'] = augmented_data[ndvi_columns].max(axis=1)

print("Dataset with new features:\n", augmented_data[['mean_ndvi', 'max_ndvi', 'label']].head())

"""Encode The Labels (1 for Rice - 0 For Cotton)"""

from sklearn.preprocessing import LabelEncoder

# Encode the label column
label_encoder = LabelEncoder()
augmented_data['label_encoded'] = label_encoder.fit_transform(augmented_data['label'])
augmented_data = augmented_data.drop('label', axis=1)

"""# Performing SMOTE Oversampling"""

from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split

# Separate features (X) and target labels (y)
X = augmented_data.drop(columns=['label_encoded'])
y = augmented_data['label_encoded']


smote = SMOTE(random_state=42)  # Initialize SMOTE
X_smote, y_smote = smote.fit_resample(X, y)  # Resample the dataset

# Combine resampled features and labels into a single dataframe
balanced_data = pd.concat([pd.DataFrame(X_smote, columns=X.columns), pd.DataFrame(y_smote, columns=['label_encoded'])], axis=1)
print("New class distribution after SMOTE:\n", balanced_data['label_encoded'].value_counts())

"""Balanced successfully!"""

# balanced_data = augmented_data.copy()

"""Prepare Data For Cross Validation"""

# Extract training and testing datasets for each combination

train_1_2 = balanced_data[(balanced_data['year'] == 2021) | (balanced_data['year'] == 2022)]
test_3 = balanced_data[balanced_data['year'] == 2023]

train_1_3 = balanced_data[(balanced_data['year'] == 2021) | (balanced_data['year'] == 2023)]
test_2 = balanced_data[balanced_data['year'] == 2022]

train_2_3 = balanced_data[(balanced_data['year'] == 2022) | (balanced_data['year'] == 2023)]
test_1 = balanced_data[balanced_data['year'] == 2021]

# Check unique labels and their counts
print("Unique labels in the dataset:", balanced_data['label_encoded'].unique())
print("Label distribution:\n", balanced_data['label_encoded'].value_counts())

"""Split The Features And Labels

# Combo 1
"""

# Define features and target
features = ndvi_columns + ['mean_ndvi', 'max_ndvi']

# Train-Test Split for Combination 1 (Train: Year 1 & 2, Test: Year 3)
X_train_1_2 = train_1_2[features]
y_train_1_2 = train_1_2['label_encoded']
X_test_3 = test_3[features]
y_test_3 = test_3['label_encoded']

"""# Combo 2"""

# Train-Test Split for Combination 2 (Train: Year 1 & 3, Test: Year 2)
X_train_1_3 = train_1_3[features]
y_train_1_3 = train_1_3['label_encoded']
X_test_2 = test_2[features]
y_test_2 = test_2['label_encoded']

"""# Combo 3"""

# Train-Test Split for Combination 3 (Train: Year 2 & 3, Test: Year 1)
X_train_2_3 = train_2_3[features]
y_train_2_3 = train_2_3['label_encoded']
X_test_1 = test_1[features]
y_test_1 = test_1['label_encoded']

print(train_1_2.columns) # check columns
print(train_1_3.columns)
print(train_2_3.columns)
print(test_1.columns)
print(test_2.columns)
print(test_3.columns)

balanced_data.head() # check data looks right

# drop year column as its not needed anymore
balanced_data = balanced_data.drop('year', axis=1)

"""# Training Random Forest Model"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix

# Initialize Random Forest model
rf = RandomForestClassifier(n_estimators=250, max_depth=30, min_samples_leaf=1, random_state=42)

"""# Combination 1 - Train on 2021-2022 - Test on 2023

Evaluation Metrics
"""

# Combination 1 (Train: Year 1 & 2, Test: Year 3)
rf.fit(X_train_1_2, y_train_1_2)
y_pred_3 = rf.predict(X_test_3)

# Evaluate the model
print("Combination 1 (Train: Year 1 & 2, Test: Year 3) Results:")
print(f"Accuracy: {accuracy_score(y_test_3, y_pred_3)}")
print(f"Precision: {classification_report(y_test_3, y_pred_3, target_names=['cotton', 'rice'], output_dict=True)['rice']['precision']}")
print(f"Recall: {classification_report(y_test_3, y_pred_3, target_names=['cotton', 'rice'], output_dict=True)['rice']['recall']}")
print(f"F1-Score: {classification_report(y_test_3, y_pred_3, target_names=['cotton', 'rice'], output_dict=True)['rice']['f1-score']}")
print(f"Report: {classification_report(y_test_3, y_pred_3, target_names=['cotton', 'rice'])}")

"""Confusion Matrix"""

# Confusion Matrix

import seaborn as sns
import matplotlib.pyplot as plt

cm_3 = confusion_matrix(y_test_3, y_pred_3)
print(cm_3)
sns.heatmap(cm_3, annot=True, fmt='d', cmap='Blues', xticklabels=['cotton', 'rice'], yticklabels=['cotton', 'rice'])
plt.title('Confusion Matrix (Year 1 & 2 Train, Year 3 Test)')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""# Combination 2 - Train on 2021-2023 - Test on 2022

Evaluation Metrics
"""

# Combination 2 (Train: Year 1 & 3, Test: Year 2)
rf.fit(X_train_1_3, y_train_1_3)
y_pred_2 = rf.predict(X_test_2)

# Evaluate the model
print("\nCombination 2 (Train: Year 1 & 3, Test: Year 2) Results:")
print(f"Accuracy: {accuracy_score(y_test_2, y_pred_2)}")
print(f"Precision: {classification_report(y_test_2, y_pred_2, target_names=['cotton', 'rice'], output_dict=True)['rice']['precision']}")
print(f"Recall: {classification_report(y_test_2, y_pred_2, target_names=['cotton', 'rice'], output_dict=True)['rice']['recall']}")
print(f"F1-Score: {classification_report(y_test_2, y_pred_2, target_names=['cotton', 'rice'], output_dict=True)['rice']['f1-score']}")
print(f"Report: {classification_report(y_test_2, y_pred_2, target_names=['cotton', 'rice'])}")

"""Confusion Matrix:"""

# Confusion Matrix
cm_2 = confusion_matrix(y_test_2, y_pred_2)
print(cm_2)
sns.heatmap(cm_2, annot=True, fmt='d', cmap='Blues', xticklabels=['cotton', 'rice'], yticklabels=['cotton', 'rice'])
plt.title('Confusion Matrix (Year 1 & 3 Train, Year 2 Test)')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""# Combination 3 - Train on 2022-2023 - Test on 2021

Evaluation Metrics
"""

# Combination 3 (Train: Year 2 & 3, Test: Year 1)
rf.fit(X_train_2_3, y_train_2_3)
y_pred_1 = rf.predict(X_test_1)

# Evaluate the model
print("\nCombination 3 (Train: Year 2 & 3, Test: Year 1) Results:")
print(f"Accuracy: {accuracy_score(y_test_1, y_pred_1)}")
print(f"Precision: {classification_report(y_test_1, y_pred_1, target_names=['cotton', 'rice'], output_dict=True)['rice']['precision']}")
print(f"Recall: {classification_report(y_test_1, y_pred_1, target_names=['cotton', 'rice'], output_dict=True)['rice']['recall']}")
print(f"F1-Score: {classification_report(y_test_1, y_pred_1, target_names=['cotton', 'rice'], output_dict=True)['rice']['f1-score']}")
print(f"Report: {classification_report(y_test_1, y_pred_1, target_names=['cotton', 'rice'])}")

"""Confusion Matrix"""

# Confusion Matrix
cm_1 = confusion_matrix(y_test_1, y_pred_1)
print(cm_1)
sns.heatmap(cm_1, annot=True, fmt='d', cmap='Blues', xticklabels=['cotton', 'rice'], yticklabels=['cotton', 'rice'])
plt.title('Confusion Matrix (Year 2 & 3 Train, Year 1 Test)')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""# Feature Importance For Random Forests"""

def plot_feature_importances(model, feature_names, title):
    """
    Plots the feature importances for a given model.

    Parameters:
    -----------
    model : sklearn.ensemble.RandomForestClassifier or similar
        The trained model object that has a `feature_importances_` attribute.

    feature_names : list of str
        A list of feature names corresponding to the input features of the model.

    title : str
        The title to be displayed on the feature importance plot.

    Returns:
    -------
        Displays a bar plot showing the importance of each feature in descending order.
        """

    importances = model.feature_importances_
    indices = np.argsort(importances)[::-1]

    # Plot the feature importances
    plt.figure(figsize=(10, 6))
    plt.title(title)
    plt.bar(range(len(importances)), importances[indices], align="center")
    plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=90)
    plt.ylabel("Importance Score")
    plt.xlabel("Features")
    plt.tight_layout()
    plt.show()

"""Indicates how much each feature contributes to the predictive power of a machine learning model. It is calculated based on how much each feature reduces impurity (e.g., Gini index or entropy) across all the decision trees."""

import numpy as np

feature_names1 = X_train_1_2.columns.tolist()
feature_names2 = X_train_1_3.columns.tolist()
feature_names3 = X_train_2_3.columns.tolist()


# Plot feature importances for Combination 1
plot_feature_importances(rf, feature_names1, "Feature Importances (Train on 2021-2022, Test on 2023)")
# Plot feature importances for Combination 2
plot_feature_importances(rf, feature_names2, "Feature Importances (Train on 2021-2023, Test on 2023)")
# Plot feature importances for Combination 3
plot_feature_importances(rf, feature_names3, "Feature Importances (Train on 2022-2023, Test on 2023)")

"""# Average Of Cross Validation Evaluations"""

# Store the evaluation metrics for each combination
accuracies = [
    accuracy_score(y_test_3, y_pred_3),  # Combination 1 Accuracy
    accuracy_score(y_test_2, y_pred_2),  # Combination 2 Accuracy
    accuracy_score(y_test_1, y_pred_1)   # Combination 3 Accuracy
]

precisions = [
    classification_report(y_test_3, y_pred_3, target_names=['cotton', 'rice'], output_dict=True)['rice']['precision'],
    classification_report(y_test_2, y_pred_2, target_names=['cotton', 'rice'], output_dict=True)['rice']['precision'],
    classification_report(y_test_1, y_pred_1, target_names=['cotton', 'rice'], output_dict=True)['rice']['precision']
]

recalls = [
    classification_report(y_test_3, y_pred_3, target_names=['cotton', 'rice'], output_dict=True)['rice']['recall'],
    classification_report(y_test_2, y_pred_2, target_names=['cotton', 'rice'], output_dict=True)['rice']['recall'],
    classification_report(y_test_1, y_pred_1, target_names=['cotton', 'rice'], output_dict=True)['rice']['recall']
]

f1_scores = [
    classification_report(y_test_3, y_pred_3, target_names=['cotton', 'rice'], output_dict=True)['rice']['f1-score'],
    classification_report(y_test_2, y_pred_2, target_names=['cotton', 'rice'], output_dict=True)['rice']['f1-score'],
    classification_report(y_test_1, y_pred_1, target_names=['cotton', 'rice'], output_dict=True)['rice']['f1-score']
]

# Calculate the average of each metric
avg_accuracy = np.mean(accuracies)
avg_precision = np.mean(precisions)
avg_recall = np.mean(recalls)
avg_f1_score = np.mean(f1_scores)

# Print the aggregated results
print(f"Overall Accuracy: {avg_accuracy}")
print(f"Overall Precision: {avg_precision}")
print(f"Overall Recall: {avg_recall}")
print(f"Overall F1-Score: {avg_f1_score}")

"""# Overall Confusion Matrix"""

# features/label
X = balanced_data[features]
y = balanced_data['label_encoded']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# train rf
rf_clf = RandomForestClassifier(random_state=42)

# Train the model
rf_clf.fit(X_train, y_train)

# Make predictions
y_pred = rf_clf.predict(X_test)

# confusion matrix plot
cm = confusion_matrix(y_test, y_pred)

# Plot
print(cm)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['cotton', 'rice'], yticklabels=['cotton', 'rice'])
plt.title('Overall')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""# **Grid Search**

# Perform GridSearch For Model
"""

from sklearn.model_selection import GridSearchCV # import libraries
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score

"""**Split Dataset Of Whole Model**"""

# Define features and target
features = ndvi_columns + ['mean_ndvi', 'max_ndvi']  # NDVI columns + engineered features
X = balanced_data[features]
y = balanced_data['label_encoded']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

"""Define Param Grid"""

# param grid defined
param_grid = {
    'n_estimators': [200, 300],
    'max_depth': [10, 20, 30],
    'min_samples_split': [2, 3, 4],
    'min_samples_leaf': [1, 2, 3]
}

"""Initialise RF"""

rf = RandomForestClassifier(random_state=42) # rf init

"""Grid Search"""

# gridsearchcv
grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=2)

# fit
grid_search.fit(X_train, y_train)

"""Print Best Params"""

best_params = grid_search.best_params_
print("Best parameters found by Grid Search:", best_params)

"""# Bagging/Boosting

Import necessary libraries
"""

from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier

# base estimator decision trees
dt_classifier = DecisionTreeClassifier(random_state=42)

# init bagging classifier
bagging_model = BaggingClassifier(n_estimators=50, random_state=42)

# set base estimator
bagging_model.base_estimator = dt_classifier

"""# Cross Validation

# Combination 1 (Train on Year 1 & 2, Test on Year 3)

Training The Model
"""

# Train-Test Split for Combination 1
X_train_1_2 = train_1_2[features]
y_train_1_2 = train_1_2['label_encoded']
X_test_3 = test_3[features]
y_test_3 = test_3['label_encoded']

# fit
bagging_model.fit(X_train_1_2, y_train_1_2)

# Predict
y_pred_3 = bagging_model.predict(X_test_3)

""" import the required libraries
"""
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

"""Evaluation Metrics"""

# Evaluate the model for Combination 1
accuracy_3 = accuracy_score(y_test_3, y_pred_3)
precision_3 = precision_score(y_test_3, y_pred_3)
recall_3 = recall_score(y_test_3, y_pred_3)
f1_3 = f1_score(y_test_3, y_pred_3)
conf_matrix_3 = confusion_matrix(y_test_3, y_pred_3)

print(f"Accuracy: {accuracy_3}")
print(f"Precision: {precision_3}")
print(f"Recall: {recall_3}")
print(f"F1-Score: {f1_3}")

"""Confusion Matrix"""

conf_matrix_3 = confusion_matrix(y_test_3, y_pred_3)
print(conf_matrix_3)
sns.heatmap(conf_matrix_3, annot=True, fmt='d', cmap='Blues', xticklabels=['cotton', 'rice'], yticklabels=['cotton', 'rice'])
plt.title('Confusion Matrix (Year 1 & 2 Train, Year 3 Test)')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""# Combination 2 (Train on Year 1 & 3, Test on Year 2)"""

X_train_1_3 = train_1_3[features]
y_train_1_3 = train_1_3['label_encoded']
X_test_2 = test_2[features]
y_test_2 = test_2['label_encoded']

# Fit the model
bagging_model.fit(X_train_1_3, y_train_1_3)

# Predict on the test set
y_pred_2 = bagging_model.predict(X_test_2)

"""Evaluation Metrics"""

# Evaluate the model for Combination 2
accuracy_2 = accuracy_score(y_test_2, y_pred_2)
precision_2 = precision_score(y_test_2, y_pred_2)
recall_2 = recall_score(y_test_2, y_pred_2)
f1_2 = f1_score(y_test_2, y_pred_2)

print(f"Accuracy: {accuracy_2}")
print(f"Precision: {precision_2}")
print(f"Recall: {recall_2}")
print(f"F1-Score: {f1_2}")

"""Confusion Matrix"""

conf_matrix_2 = confusion_matrix(y_test_2, y_pred_2)
print(f"Confusion Matrix:\n{conf_matrix_2}")
sns.heatmap(conf_matrix_2, annot=True, fmt='d', cmap='Blues', xticklabels=['cotton', 'rice'], yticklabels=['cotton', 'rice'])
plt.title('Confusion Matrix (Year 1 & 3 Train, Year 2 Test)')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""# Combination 3 (Train on Year 2 & 3, Test on Year 1)"""

X_train_2_3 = train_2_3[features]
y_train_2_3 = train_2_3['label_encoded']
X_test_1 = test_1[features]
y_test_1 = test_1['label_encoded']

# Fit the model
bagging_model.fit(X_train_2_3, y_train_2_3)

# Predict on the test set
y_pred_1 = bagging_model.predict(X_test_1)

"""Evaluation Metrics"""

# Evaluate the model for Combination 3
accuracy_1 = accuracy_score(y_test_1, y_pred_1)
precision_1 = precision_score(y_test_1, y_pred_1)
recall_1 = recall_score(y_test_1, y_pred_1)
f1_1 = f1_score(y_test_1, y_pred_1)


print(f"Accuracy: {accuracy_1}")
print(f"Precision: {precision_1}")
print(f"Recall: {recall_1}")
print(f"F1-Score: {f1_1}")

"""Confusion Matrix"""

conf_matrix_1 = confusion_matrix(y_test_1, y_pred_1)
print(f"Confusion Matrix:\n{conf_matrix_1}")
sns.heatmap(conf_matrix_1, annot=True, fmt='d', cmap='Blues', xticklabels=['cotton', 'rice'], yticklabels=['cotton', 'rice'])
plt.title('Confusion Matrix (Year 2 & 3 Train, Year 1 Test)')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""# Cross Validation Overall Metrics

Append for combo 1
"""

# lists
accuracies = []
precisions = []
recalls = []
f1_scores = []
conf_matrices = []

# combo 1
bagging_model.fit(X_train_1_2, y_train_1_2)
y_pred_3 = bagging_model.predict(X_test_3)

accuracy_3 = accuracy_score(y_test_3, y_pred_3)
precision_3 = precision_score(y_test_3, y_pred_3)
recall_3 = recall_score(y_test_3, y_pred_3)
f1_3 = f1_score(y_test_3, y_pred_3)
conf_matrix_3 = confusion_matrix(y_test_3, y_pred_3)

# append
accuracies.append(accuracy_3)
precisions.append(precision_3)
recalls.append(recall_3)
f1_scores.append(f1_3)
conf_matrices.append(conf_matrix_3)

"""Append for combo 2"""

# combo 2
bagging_model.fit(X_train_1_3, y_train_1_3)
y_pred_2 = bagging_model.predict(X_test_2)

accuracy_2 = accuracy_score(y_test_2, y_pred_2)
precision_2 = precision_score(y_test_2, y_pred_2)
recall_2 = recall_score(y_test_2, y_pred_2)
f1_2 = f1_score(y_test_2, y_pred_2)
conf_matrix_2 = confusion_matrix(y_test_2, y_pred_2)

# append
accuracies.append(accuracy_2)
precisions.append(precision_2)
recalls.append(recall_2)
f1_scores.append(f1_2)
conf_matrices.append(conf_matrix_2)

"""Append for combo 3"""

# combo 3
bagging_model.fit(X_train_2_3, y_train_2_3)
y_pred_1 = bagging_model.predict(X_test_1)

accuracy_1 = accuracy_score(y_test_1, y_pred_1)
precision_1 = precision_score(y_test_1, y_pred_1)
recall_1 = recall_score(y_test_1, y_pred_1)
f1_1 = f1_score(y_test_1, y_pred_1)
conf_matrix_1 = confusion_matrix(y_test_1, y_pred_1)

# append
accuracies.append(accuracy_1)
precisions.append(precision_1)
recalls.append(recall_1)
f1_scores.append(f1_1)
conf_matrices.append(conf_matrix_1)

# Aggregate metrics.....
avg_accuracy = np.mean(accuracies)
avg_precision = np.mean(precisions)
avg_recall = np.mean(recalls)
avg_f1_score = np.mean(f1_scores)

# Print aggregated metrics
print(f"Overall Accuracy: {avg_accuracy}")
print(f"Overall Precision: {avg_precision}")
print(f"Overall Recall: {avg_recall}")
print(f"Overall F1-Score: {avg_f1_score}")

"""# Overall Confusion Matrix"""

# features/label
X = balanced_data[features]
y = balanced_data['label_encoded']

# split data 80/20
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# base estimator decision trees
dt_classifier = DecisionTreeClassifier(random_state=42)

# init bagging classifier
bagging_model = BaggingClassifier(n_estimators=50, random_state=42)

# set base estimator
bagging_model.base_estimator = dt_classifier

"""fit and predict"""

# Fit the model
bagging_model.fit(X_train,y_train)

# Predict on the test set
y_pred = bagging_model.predict(X_test)

"""Plot Confusion Matrix"""

# Calculate
cm22 = confusion_matrix(y_test, y_pred)

# Plot
plt.figure(figsize=(8, 6))
sns.heatmap(cm22, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y), yticklabels=np.unique(y))
plt.title('Confusion Matrix - Bagging with Decision Tree')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.show()

"""# **Grid Search**

Import Libraries
"""

from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# features/label
X = balanced_data[features]
y = balanced_data['label_encoded']

# split data 80/20
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# param grid
param_grid = {
    'n_estimators': [50, 100, 150],  # Number of base estimators in Bagging
    'max_samples': [0.5, 0.7, 0.8],   # Fraction of samples to draw for each base estimator
    ' base_estimator__max_depth': [0.5, 0.7, 0.8],  # Fraction of features to draw for each base estimator
}

"""Initialise The Classifiers"""

# initialise bagging classifier

dt_classifier = DecisionTreeClassifier(random_state=42)
bagging_model = BaggingClassifier(random_state=42)
bagging_model.base_estimator = dt_classifier

# grid search cv
grid_search = GridSearchCV(estimator=bagging_model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)

# fit
grid_search.fit(X_train, y_train)

# print the best parameters
print(f"Best Parameters: {grid_search.best_params_}")